{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intellectual-battlefield",
   "metadata": {},
   "source": [
    "This script describes how to load the condensed json versions of the Gaussian process (GP) interpolation models described in [link to paper]. The models are originally made using the `scikit-learn` Gaussian process regressor module (https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.html). The json versions are much more storage-efficient and simply load the hyperparameters of the trained models into a newly instantiated GP regressor object.\n",
    "\n",
    "The models are first organized into different families by viewing angle. Each viewing angle directory contains time-step subdirectories which host the optimized hyperparameters for interpolation at the given time step. The final light curve product is produced by \"stitching together\" the separate predictions produced from the interpolators at each separate time step. \n",
    "\n",
    "The example below shows how to load the models for the pole-on viewing angle bin (between 0 and 15.64 degrees) and create a prediction for an off-sample parameter combination. The final light curve is stitched together from the 191 separate time step predictions. The light curve output can be compared to the bottom half of Figure 4 in [link to paper].\n",
    "\n",
    "This script can be generally applied to all viewing angle model families. It is also capable of generating a light curve using only a subset of the time steps in the respective viewing angle directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "comic-bearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter notebook describing how to load and make predictions using json models\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import save_sklearn_gp as ssg\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import cholesky, solve_triangular, cho_solve\n",
    "\n",
    "# making a size (9, 5) array with each row having 5 input parameters (md, vd, mw, vw, wav) for all wavelength bands\n",
    "\n",
    "times = np.logspace(np.log10(0.125), np.log10(7.6608262), 191)\n",
    "\n",
    "inputs = np.array([0.097050, 0.197642, 0.083748, 0.297978]) # parameters used for off-sample prediction in paper\n",
    "wavs = np.array([476., 621., 754., 900., 1020., 1220., 1630., 2190., 4493.]).reshape(9, 1)\n",
    "inputs = np.tile(inputs, wavs.shape[0]).reshape(-1, 4)\n",
    "inputs = np.hstack((inputs, wavs))\n",
    "\n",
    "# loading all the models from the family trained using a pole-on viewing angle\n",
    "\n",
    "files = glob.glob('theta00deg/*')\n",
    "files.sort() # sorting is necessary! otherwise time will be out of order\n",
    "\n",
    "# loop through all the individual time steps, making a prediction at each\n",
    "\n",
    "for file in files:\n",
    "\tfname = file+'/model'\n",
    "\tmodel = ssg.load_gp(fname) # loading Gaussian Process from hyperparameters saved in .json format\n",
    "\tK = model.kernel_(model.X_train_) # setting up the kernel\n",
    "\tK[np.diag_indices_from(K)] += model.alpha\n",
    "\tmodel.L_ = cholesky(K, lower=True) # recalculating L matrix since this is what makes the pickled models bulky\n",
    "\tmodel._K_inv = None # has to be set to None so the GP knows to re-calculate matrices used for uncertainty\n",
    "\tpred, err = model.predict(inputs, return_std=True) # returns prediction and uncertainty\n",
    "\ttry:\n",
    "\t\tlc = np.append(lc, pred[None, :], axis=0)\n",
    "\t\terrs = np.append(errs, err[None, :], axis=0)\n",
    "\texcept NameError:\n",
    "\t\tlc = pred[None, :] # if first time point, initializes the light curve array\n",
    "\t\terrs = err[None, :] # same as above, but for errors\n",
    "for band in range(lc.shape[1]):\n",
    "\tplt.plot(times, lc[:, band])\n",
    "\tplt.fill_between(times, lc[:, band]-errs[:, band], lc[:, band]+errs[:, band], color='red', alpha=0.3)\n",
    "plt.xscale('log')\n",
    "plt.savefig('pred_compact.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-scout",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
